{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS Data Set importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 141)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(r'C:\\Users\\srfzx\\Downloads\\ECG5000\\ECG5000_TRAIN.csv', nrows=50000)\n",
    "df2 = pd.read_csv(r'C:\\Users\\srfzx\\Downloads\\ECG5000\\ECG5000_TEST.csv', nrows=50000)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.target\n",
    "X_train = df.drop(['target'],axis=1)\n",
    "y_test = df2.target\n",
    "X_test = df2.drop(['target'],axis=1)\n",
    "X_test = df2.drop(['id'],axis=1)\n",
    "X_test = X_test.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = ['att1','att2','Peath','Petal Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c63169bb0dd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeat_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lol'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att131</th>\n",
       "      <th>att132</th>\n",
       "      <th>att133</th>\n",
       "      <th>att134</th>\n",
       "      <th>att135</th>\n",
       "      <th>att136</th>\n",
       "      <th>att137</th>\n",
       "      <th>att138</th>\n",
       "      <th>att139</th>\n",
       "      <th>att140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160348</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>1.284825</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491173</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966606</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0 -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1 -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2 -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3  0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4  0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "\n",
       "       att8      att9     att10  ...    att131    att132    att133    att134  \\\n",
       "0 -1.818286 -1.250522 -0.477492  ...  0.160348  0.792168  0.933541  0.796958   \n",
       "1 -0.992258 -0.754680  0.042321  ...  0.560327  0.538356  0.656881  0.787490   \n",
       "2 -1.490659 -1.183580 -0.394229  ...  1.284825  0.886073  0.531452  0.311377   \n",
       "3 -1.671131 -1.333884 -0.965629  ...  0.491173  0.350816  0.499111  0.600345   \n",
       "4 -1.783423 -1.594450 -0.753199  ...  0.966606  1.148884  0.958434  1.059025   \n",
       "\n",
       "     att135    att136    att137    att138    att139    att140  \n",
       "0  0.578621  0.257740  0.228077  0.123431  0.925286  0.193137  \n",
       "1  0.724046  0.555784  0.476333  0.773820  1.119621 -1.436250  \n",
       "2 -0.021919 -0.713683 -0.532197  0.321097  0.904227 -0.421797  \n",
       "3  0.842069  0.952074  0.990133  1.086798  1.403011 -0.383564  \n",
       "4  1.371682  1.277392  0.960304  0.971020  1.614392  1.421456  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaine =np.zeros(shape=(1,140))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaine[0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5., 3., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "        5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaine[0,3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in range(0,140):\n",
    "    k=k+1\n",
    "    chaine[0,i] = int(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "         23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "         34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "         45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "         56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "         67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "         78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "         89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "        100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "        111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "        122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "        133., 134., 135., 136., 137., 138., 139., 140.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-896fbdc075c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mchaine\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mchaine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchaine\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"att\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"'\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchaine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "chaine =np.zeros(shape=(1,140))\n",
    "for i in range(1,140):\n",
    "    chaine = chaine + \"\"+ \"att\" + str(i)+\"'\"+\",\"\n",
    "print (chaine)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = [chaine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = chaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "         23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,\n",
       "         34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,\n",
       "         45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,\n",
       "         56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,  66.,\n",
       "         67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,  77.,\n",
       "         78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
       "         89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99.,\n",
       "        100., 101., 102., 103., 104., 105., 106., 107., 108., 109., 110.,\n",
       "        111., 112., 113., 114., 115., 116., 117., 118., 119., 120., 121.,\n",
       "        122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n",
       "        133., 134., 135., 136., 137., 138., 139., 140.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 141)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(r'C:\\Users\\srfzx\\Downloads\\ECG5000\\ECG5000_TRAIN.csv', nrows=50000)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-4b49bc6e26d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeat_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "feat_labels.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirrabak=X_train.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('att1', 0.0011014475957030982)\n",
      "('att2', 0.0011617390592248975)\n",
      "('att3', 0.0027440352888324065)\n",
      "('att4', 0.011155642626652506)\n",
      "('att5', 0.025891801697567454)\n",
      "('att6', 0.0029292339669962815)\n",
      "('att7', 0.0025594464162734987)\n",
      "('att8', 0.0041592073199247384)\n",
      "('att9', 0.005092813361708993)\n",
      "('att10', 0.00738011392108558)\n",
      "('att11', 0.010411494117858461)\n",
      "('att12', 0.009647965108322769)\n",
      "('att13', 0.002948267619504618)\n",
      "('att14', 0.0015675469442347474)\n",
      "('att15', 0.0012651062683758942)\n",
      "('att16', 0.0009866345408598095)\n",
      "('att17', 0.0012081125944659722)\n",
      "('att18', 0.0013895380839372812)\n",
      "('att19', 0.0012961564069668033)\n",
      "('att20', 0.0015914798574326286)\n",
      "('att21', 0.0018434694704880636)\n",
      "('att22', 0.0019021561804005826)\n",
      "('att23', 0.002311914341893938)\n",
      "('att24', 0.003471269833398905)\n",
      "('att25', 0.004209078225520273)\n",
      "('att26', 0.0041364938920026295)\n",
      "('att27', 0.004992144065999707)\n",
      "('att28', 0.005280577185165576)\n",
      "('att29', 0.006917441363085659)\n",
      "('att30', 0.007729050463085196)\n",
      "('att31', 0.011399914508487397)\n",
      "('att32', 0.013121786433308665)\n",
      "('att33', 0.012991708540080681)\n",
      "('att34', 0.014396087670852249)\n",
      "('att35', 0.011556523562787828)\n",
      "('att36', 0.008750502567379125)\n",
      "('att37', 0.007664333460672331)\n",
      "('att38', 0.006700500562225498)\n",
      "('att39', 0.005985688627331469)\n",
      "('att40', 0.004292162351166284)\n",
      "('att41', 0.0036364972666156656)\n",
      "('att42', 0.002337230737845007)\n",
      "('att43', 0.0014820889566545452)\n",
      "('att44', 0.0014618767952398546)\n",
      "('att45', 0.0010005331648211065)\n",
      "('att46', 0.0008321888765828849)\n",
      "('att47', 0.0009692025289580851)\n",
      "('att48', 0.0009778311359973561)\n",
      "('att49', 0.001038957674219446)\n",
      "('att50', 0.0017711774328862985)\n",
      "('att51', 0.0022563315541933404)\n",
      "('att52', 0.002268162765093664)\n",
      "('att53', 0.002304859520242238)\n",
      "('att54', 0.0026246163818039042)\n",
      "('att55', 0.002157719565177457)\n",
      "('att56', 0.001845260396818565)\n",
      "('att57', 0.0019640970587471397)\n",
      "('att58', 0.0015237950211422007)\n",
      "('att59', 0.0018469164022914388)\n",
      "('att60', 0.0016550460169046546)\n",
      "('att61', 0.0020460992645327143)\n",
      "('att62', 0.002079841428127242)\n",
      "('att63', 0.001866282874135212)\n",
      "('att64', 0.0016011246255524926)\n",
      "('att65', 0.0015356545620093633)\n",
      "('att66', 0.0014317712614584372)\n",
      "('att67', 0.001449185498094322)\n",
      "('att68', 0.0014333437342402145)\n",
      "('att69', 0.0017894719464254896)\n",
      "('att70', 0.0016922949717276927)\n",
      "('att71', 0.0013721269016169328)\n",
      "('att72', 0.0012489663788475117)\n",
      "('att73', 0.001347626693543217)\n",
      "('att74', 0.0011895898727566547)\n",
      "('att75', 0.001112448952092759)\n",
      "('att76', 0.0015888679303367897)\n",
      "('att77', 0.0015725419826489596)\n",
      "('att78', 0.0013548101512854012)\n",
      "('att79', 0.001978381745103321)\n",
      "('att80', 0.0016955034614232146)\n",
      "('att81', 0.0013736547545446555)\n",
      "('att82', 0.0014136709954877375)\n",
      "('att83', 0.0013334332192226485)\n",
      "('att84', 0.0015670859700118477)\n",
      "('att85', 0.0014857381670571883)\n",
      "('att86', 0.0015771624907898153)\n",
      "('att87', 0.0023998173422646223)\n",
      "('att88', 0.0017726285421849524)\n",
      "('att89', 0.0020126760160863156)\n",
      "('att90', 0.0021452938380752927)\n",
      "('att91', 0.002188491647227197)\n",
      "('att92', 0.001980346916391273)\n",
      "('att93', 0.0017922466858570454)\n",
      "('att94', 0.0030632266524817935)\n",
      "('att95', 0.0023362733992034817)\n",
      "('att96', 0.0025627024403088853)\n",
      "('att97', 0.0025398462477157517)\n",
      "('att98', 0.002616660634147254)\n",
      "('att99', 0.0028088067539177746)\n",
      "('att100', 0.0023944020109163493)\n",
      "('att101', 0.003492919995830437)\n",
      "('att102', 0.004616536591585637)\n",
      "('att103', 0.0126976883161414)\n",
      "('att104', 0.02681011342774503)\n",
      "('att105', 0.03801959271422931)\n",
      "('att106', 0.023796669177327933)\n",
      "('att107', 0.013596172876837918)\n",
      "('att108', 0.003431300833823926)\n",
      "('att109', 0.0017353940284622032)\n",
      "('att110', 0.002829704643981745)\n",
      "('att111', 0.003343073906331232)\n",
      "('att112', 0.004635562077824786)\n",
      "('att113', 0.0044026214784412465)\n",
      "('att114', 0.004155041563954273)\n",
      "('att115', 0.005954720819952884)\n",
      "('att116', 0.01601784556647368)\n",
      "('att117', 0.03281371817468052)\n",
      "('att118', 0.03209376212150384)\n",
      "('att119', 0.02677265212041898)\n",
      "('att120', 0.025596843956256977)\n",
      "('att121', 0.012096393169931358)\n",
      "('att122', 0.005378747725834834)\n",
      "('att123', 0.004768565274517684)\n",
      "('att124', 0.0044041570685734764)\n",
      "('att125', 0.00442867380125712)\n",
      "('att126', 0.005165156087132895)\n",
      "('att127', 0.005004553107048442)\n",
      "('att128', 0.004561951155619198)\n",
      "('att129', 0.002908212555449433)\n",
      "('att130', 0.002100154965882745)\n",
      "('att131', 0.0022585882152297725)\n",
      "('att132', 0.014706724300033525)\n",
      "('att133', 0.04058052779357066)\n",
      "('att134', 0.05419478391290305)\n",
      "('att135', 0.05789331266497658)\n",
      "('att136', 0.06110482627863348)\n",
      "('att137', 0.054148601512744865)\n",
      "('att138', 0.020213817155129325)\n",
      "('att139', 0.0089259054593921)\n",
      "('att140', 0.003499339090990561)\n"
     ]
    }
   ],
   "source": [
    "# RFC erstellen\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# RFC antrainieren\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Print the name and gini importance of each feature\n",
    "for feature in zip(dirrabak, clf.feature_importances_):\n",
    "  print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=10000, n_jobs=-1,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=0, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.01)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gewicht erstellen\n",
    "sfm = SelectFromModel(clf, threshold=0.01)\n",
    "\n",
    "# Selector antrainieren\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"'att1','att2','att3','att4','att5','att6','att7','att8','att9','att10','att11','att12','att13','att14','att15','att16','att17','att18','att19','att20','att21','att22','att23','att24','att25','att26','att27','att28','att29','att30','att31','att32','att33','att34','att35','att36','att37','att38','att39','att40','att41','att42','att43','att44','att45','att46','att47','att48','att49','att50','att51','att52','att53','att54','att55','att56','att57','att58','att59','att60','att61','att62','att63','att64','att65','att66','att67','att68','att69','att70','att71','att72','att73','att74','att75','att76','att77','att78','att79','att80','att81','att82','att83','att84','att85','att86','att87','att88','att89','att90','att91','att92','att93','att94','att95','att96','att97','att98','att99','att100','att101','att102','att103','att104','att105','att106','att107','att108','att109','att110','att111','att112','att113','att114','att115','att116','att117','att118','att119','att120','att121','att122','att123','att124','att125','att126','att127','att128','att129','att130','att131','att132','att133','att134','att135','att136','att137','att138','att139','att140'\", 0.0011014475957030982)\n"
     ]
    }
   ],
   "source": [
    "# RFC erstellen\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# RFC antrainieren\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(dirrabak, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature gewicht feststellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                 class_weight=None,\n",
       "                                                 criterion='gini',\n",
       "                                                 max_depth=None,\n",
       "                                                 max_features='auto',\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=10000, n_jobs=-1,\n",
       "                                                 oob_score=False,\n",
       "                                                 random_state=0, verbose=0,\n",
       "                                                 warm_start=False),\n",
       "                max_features=None, norm_order=1, prefit=False, threshold=0.01)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gewicht erstellen\n",
    "sfm = SelectFromModel(clf, threshold=0.01)\n",
    "\n",
    "# Selector antrainieren\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view feature die mehr als gewicht (0.15) haben "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "att4\n",
      "att5\n",
      "att11\n",
      "att31\n",
      "att32\n",
      "att33\n",
      "att34\n",
      "att35\n",
      "att103\n",
      "att104\n",
      "att105\n",
      "att106\n",
      "att107\n",
      "att116\n",
      "att117\n",
      "att118\n",
      "att119\n",
      "att120\n",
      "att121\n",
      "att132\n",
      "att133\n",
      "att134\n",
      "att135\n",
      "att136\n",
      "att137\n",
      "att138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(dirrabak[feature_list_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neue Data mit selektierten Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(X_important_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 26)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_important_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain mit selektierten features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
       "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beide Classifiers vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 140)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9364444444444444"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test )\n",
    "accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "accuracy_score(y_test, y_important_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded 140 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.969877</td>\n",
       "      <td>0.948019</td>\n",
       "      <td>0.992767</td>\n",
       "      <td>2627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.917679</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>1590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.281081</td>\n",
       "      <td>0.297143</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>0.900667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.522653</td>\n",
       "      <td>0.537451</td>\n",
       "      <td>0.512561</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.898403</td>\n",
       "      <td>0.897754</td>\n",
       "      <td>0.900667</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall      support\n",
       "1             0.969877   0.948019  0.992767  2627.000000\n",
       "2             0.885417   0.917679  0.855346  1590.000000\n",
       "3             0.410256   0.457143  0.372093    86.000000\n",
       "4             0.288889   0.281081  0.297143   175.000000\n",
       "5             0.058824   0.083333  0.045455    22.000000\n",
       "accuracy      0.900667   0.900667  0.900667     0.900667\n",
       "macro avg     0.522653   0.537451  0.512561  4500.000000\n",
       "weighted avg  0.898403   0.897754  0.900667  4500.000000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model = clf.fit(X_train,y_train)\n",
    "predict = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report \n",
    "#print(classification_report(y_test, predict))\n",
    "report = classification_report(y_test, predict, output_dict=True)\n",
    "report = classification_report(y_test, predict, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded 26 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953645</td>\n",
       "      <td>0.936834</td>\n",
       "      <td>0.971070</td>\n",
       "      <td>2627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869903</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.845283</td>\n",
       "      <td>1590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310559</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.209945</td>\n",
       "      <td>0.217143</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.879778</td>\n",
       "      <td>0.879778</td>\n",
       "      <td>0.879778</td>\n",
       "      <td>0.879778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.478820</td>\n",
       "      <td>0.484746</td>\n",
       "      <td>0.473930</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.878547</td>\n",
       "      <td>0.878257</td>\n",
       "      <td>0.879778</td>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall      support\n",
       "1             0.953645   0.936834  0.971070  2627.000000\n",
       "2             0.869903   0.896000  0.845283  1590.000000\n",
       "3             0.310559   0.333333  0.290698    86.000000\n",
       "4             0.213483   0.209945  0.217143   175.000000\n",
       "5             0.046512   0.047619  0.045455    22.000000\n",
       "accuracy      0.879778   0.879778  0.879778     0.879778\n",
       "macro avg     0.478820   0.484746  0.473930  4500.000000\n",
       "weighted avg  0.878547   0.878257  0.879778  4500.000000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
    "model = clf.fit(X_important_train,y_train)\n",
    "predict = model.predict(X_important_test)\n",
    "from sklearn.metrics import classification_report \n",
    "#print(classification_report(y_test, predict))\n",
    "report = classification_report(y_test, predict, output_dict=True)\n",
    "report = classification_report(y_test, predict, output_dict=True)\n",
    "df2 = pd.DataFrame(report).transpose()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
